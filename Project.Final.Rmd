---
title: "Project.Final"
author: "Leslie Speight Youtsey and Liz Weatherup"
date: "11/13/2020"
output:
  html_document:
    df_print: paged
---

# Title: Fluxes in the ocean 

# Abstract: 

# Introduction: 

  Many environmental and anthropogenic activities can affect the amount of nutrient runoff into water ecosystems (1). The amount of nitrogen (N) and phosphorus (P) entering an ecosystem can affect their flux as well as many other environmental impacts (1). In a study done in Erhai Lake, it showed that nitrogen and phosphorus diffusion flux can affect the biomass and population of autotrophs in this lake that can result in algal blooms (2). We can expect a similar trend to happen in the ocean, but due to the open oceans variability, it is much easier to study these trends in a lake system. Nitrogen and phosphorus fluxes are influenced by internal and external factors such as: nutritive salt concentration, DO, pH, algal biomass, microbial activity, chlorophyll a, etc. (2). It is important to look at these controlling factors and how they will affect the fluxes and the ecosystem as a whole. For example, Erhai Lake is in a transition phase from mesotrophic to eutrophic bodies of water due to the increase of nutritive salts affecting the N and P diffusive fluxes (2). 
  
  Carbon also enters the ocean and causes stress to organisms as it increases ocean acidity, but it enters through the earth’s atmosphere (3). The amount of carbon in the atmosphere has been steadily increasing overtime due to the large input of fossil fuels into the environment (3). Again, carbon input, like nitrogen and phosphorus is caused by anthropogenic stress.
  
  Nitrogen, phosphorus, and carbon are all connected in that they relate to the biological pump and the solubility pump. They all interact with marine organisms that use them for growth and energy, and they are eventually respired or excreted out of these organisms to sink to depth (4). Ocean physics and the solubility pump also helps to aid these to sink to depth, especially in areas of deep, cold water mixing, like the Southern Ocean (4).  The sinking of this nitrogen, phosphorus, and carbon is flux (4). These fluxes are important, especially when it comes to carbon sequestration, which has often been a hot topic as a way to decrease the amount of carbon in the atmosphere. Typically, these fluxes tend to decrease with depth due to the carbon, phosphorus, and nitrogen being used by organisms along the way down to the benthos (4). 
  
  The best way to measure these fluxes is using sediment traps. Sediments traps are a method for collecting and determining the sinking fluxes of particulate matter, carbon, and nitrogen in the sea. These values are expressed as mg m^-2 day^-1. Total particulate mass flux is defined as the amount of sinking particulate matter passing through a depth level as ( mg dry weight m^-2 day^-2). Total particulate carbon flux is defined as the amount of sinking particulate organic carbon passing through a depth level (mg carbon m^-2 day^-1). Total nitrogen mass flux is defined as the amount of sinking particulate organic nitrogen passing through a depth level (mg nitrogen m^-2 day^-1) (5).
  
  In our study we looked at fluxes of nitrogen, phosphorus, carbon, and mass in the Bermuda Atlantic Time-series through The Joint Global Ocean Flux Study. The Joint Global Ocean FLux Study (JGOFS) is a multi-disciplinary and international study that aims to understand the ocean's role in global carbon and nutrient cycles. One of the objectives of the U.S JGOFS- sponsored Bermuda Atlantic Time-series Study (BATS) is to “observe and interpret the annual and interannual variability in the rates of particle flux and the apparent rates of particle remineralization over the entire water column”. BATS began in October 1988 and is through December 2016.(6)
  
  Our objectives include evaluating how depth affects each flux and how each flux affects mass flux. 
    
# Toolbox discussion: 

Over the course of MSCI 504, we learn key statistical topics and skills, including, but not limited too, statistical inference, distributional assumption and rational, confidence intervals, hypothesis testing, linear and multiple regression, analysis of variance (ANOVA), and analysis of covariance (ANCOVA). All of these course topics are included in this project. 
Our data included the values of carbon, nitrogen, phosphorus, and mass flux sampled at various depths along multiple cruises. The mean and standard deviation of each flux at each depth was taken. To analyze the structure and distribution of our sample, histograms and boxplots were made. Hypothesis testing in the form of paired sample t-test. Linear and multiple regression was performed to predict mass flux. An ANOVA test was performed to compare large vs small models. An ANCOVA model was done to take into account covariance and blocking factors within our data.

# Description:

Our Data was subset from the original data set to exclude all blank columns and include just the average flux values from each of the samples taken at a specific cruise, location, and depth. Each Flux was then subset into their own data frame and then each depth was subset into their own dataframe. These data frames were then used to take statistical inference in the form of number of observations, means and standard error from each flux at each depth. The means were then used to visually access the difference in each depth of each flux in the form of barplots. To check for distribution normality and outliers, histograms and boxplots for each flux at each depth were created. Log transformations for all flux values were done to increase normality and eventually linearity in regression models. To test for significant difference in flux values as depth increases, paired sample t-test were performed. Two paired sample t-test was performed for each flux, comparing flux values at 150 meters to 200 meters and 200 meters to 300 meters. All 400 meter values were excluded from hypothesis testing due to low observational units and non-Gaussian distributions, even after log transformations. A paired sample t-test was chosen because some. samples were collected on the same cruise and at the same location. So for each flux value at one depth, there was a flux value collected at a different depth at the same location. Data frames for each paired sample t-test were merged based on cruise, year, and location to have the same number of values. The dbar (ybar_1 - ybar_2) was created for each  distribution of the difference between each pair …. To be continued… simple linear regression … collinearity …. Multiple regression … anova…. Ancova.  

# Implementation:

*See Appendix for all code*

### Reading csv data in 

```{r, echo=FALSE}
rm(list=ls(all=TRUE))  #Housekeeping: clear out old files

options(warn = -1)
knitr::opts_chunk$set(echo = T, fig.height=6, fig.width=8, warning = F, message = F) 
```

```{r, eval=TRUE, echo=FALSE}
bats_flux <- read.csv("bats_flux.csv")

delete.na <- function(DF, n=0) {
  DF[rowSums(is.na(DF)) <= n,]
} #Function that takes rows out that contains NAs 
bats_flux.noNA <- delete.na(bats_flux) # Take out rows containing NAs 

# Too many observations taken out, lets subset a new data frame

Data <- subset(bats_flux,select = c("cr","dep","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2","M_avg","C_avg","N_avg","P_avg"))
Data.noNA <- delete.na(Data)

# now we can use Data.noNA to compare each flux to one another, since no flux contains NAs

```

Here is what our data looks like 

```{r, echo = FALSE}
head(Data.noNA)
```

#### Subsetted each flux out seperatly 

```{r,eval=TRUE, echo=FALSE}
# separate each flux into its own dataframe 
# delete rows that contain NAs 
C_flux.data <- delete.na(subset(Data,select = c("cr","dep","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2","C_avg")))
N_flux.data <- delete.na(subset(Data,select = c("cr","dep","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2","N_avg")))
P_flux.data <- delete.na(subset(Data,select = c("cr","dep","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2","P_avg")))
M_flux.data <- delete.na(subset(Data,select = c("cr","dep","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2","M_avg")))
```

#### Subsetted each depth and Renaming Columns 

```{r,eval=TRUE, echo=FALSE}
# Subset each depth and rename columns 
library(tidyverse)
library(dplyr)
# use tideyverse instead
C_flux.depth.150 <- subset(C_flux.data, dep == 150)
C_flux.depth.150 <- rename(C_flux.depth.150,c("dep.150" = "dep"))
C_flux.depth.150 <- rename(C_flux.depth.150, c("C_avg.150" = "C_avg" ))
C_flux.depth.200 <- subset(C_flux.data, dep == 200)
C_flux.depth.200 <- rename(C_flux.depth.200, c("dep.200"="dep"))
C_flux.depth.200 <- rename(C_flux.depth.200, c("C_avg.200" ="C_avg"))
C_flux.depth.300 <- subset(C_flux.data, dep == 300)
C_flux.depth.300 <- rename(C_flux.depth.300, c("dep.300"="dep"))
C_flux.depth.300 <- rename(C_flux.depth.300, c("C_avg.300" ="C_avg"))
C_flux.depth.400 <- subset(C_flux.data, dep == 400)
C_flux.depth.400 <- rename(C_flux.depth.400, c("dep.400"="dep"))
C_flux.depth.400 <- rename(C_flux.depth.400, c("C_avg.400" ="C_avg"))
```

```{r,eval=TRUE, echo=FALSE}
N_flux.depth.150 <- subset(N_flux.data, dep == 150)
N_flux.depth.150 <- rename(N_flux.depth.150, c("dep.150"="dep"))
N_flux.depth.150 <- rename(N_flux.depth.150, c("N_avg.150" ="N_avg"))
N_flux.depth.200 <- subset(N_flux.data, dep == 200)
N_flux.depth.200 <- rename(N_flux.depth.200, c("dep.200"="dep"))
N_flux.depth.200 <- rename(N_flux.depth.200, c("N_avg.200" ="N_avg"))
N_flux.depth.300 <- subset(N_flux.data, dep == 300)
N_flux.depth.300 <- rename(N_flux.depth.300, c("dep.300"="dep"))
N_flux.depth.300 <- rename(N_flux.depth.300, c("N_avg.300" ="N_avg"))
N_flux.depth.400 <- subset(N_flux.data, dep == 400)
N_flux.depth.400 <- rename(N_flux.depth.400, c("dep.400"="dep"))
N_flux.depth.400 <- rename(N_flux.depth.400, c("N_avg.400" ="N_avg"))
```

```{r,eval=TRUE, echo=FALSE}
P_flux.depth.150 <- subset(P_flux.data, dep == 150)
P_flux.depth.150 <- rename(P_flux.depth.150, c("dep.150"="dep"))
P_flux.depth.150 <- rename(P_flux.depth.150, c("P_avg.150" ="P_avg"))
P_flux.depth.200 <- subset(P_flux.data, dep == 200)
P_flux.depth.200 <- rename(P_flux.depth.200, c("dep.200"="dep"))
P_flux.depth.200 <- rename(P_flux.depth.200, c("P_avg.200" ="P_avg"))
P_flux.depth.300 <- subset(P_flux.data, dep == 300)
P_flux.depth.300 <- rename(P_flux.depth.300, c("dep.300"="dep"))
P_flux.depth.300 <- rename(P_flux.depth.300, c("P_avg.300" ="P_avg"))
P_flux.depth.400 <- subset(P_flux.data, dep == 400)
P_flux.depth.400 <- rename(P_flux.depth.400, c("dep.400"="dep"))
P_flux.depth.400 <- rename(P_flux.depth.400, c("P_avg.400" ="P_avg"))
```

```{r,eval=TRUE, echo=FALSE}
M_flux.depth.150 <- subset(M_flux.data, dep == 150)
M_flux.depth.150 <- rename(M_flux.depth.150, c("dep.150"="dep"))
M_flux.depth.150 <- rename(M_flux.depth.150, c("M_avg.150" ="M_avg"))
M_flux.depth.200 <- subset(M_flux.data, dep == 200)
M_flux.depth.200 <- rename(M_flux.depth.200, c("dep.200"="dep"))
M_flux.depth.200 <- rename(M_flux.depth.200, c("M_avg.200" ="M_avg"))
M_flux.depth.300 <- subset(M_flux.data, dep == 300)
M_flux.depth.300 <- rename(M_flux.depth.300, c("dep.300"="dep"))
M_flux.depth.300 <- rename(M_flux.depth.300, c("M_avg.300" ="M_avg"))
M_flux.depth.400 <- subset(M_flux.data, dep == 400)
M_flux.depth.400 <- rename(M_flux.depth.400, c("dep.400"="dep"))
M_flux.depth.400 <- rename(M_flux.depth.400, c("M_avg.400" ="M_avg"))
```

### Bar plots to access relationship between fluxes and depths 

n values for C-flux at each depth

```{r, echo=FALSE}
#n values for C-flux
length(C_flux.depth.150$C_avg.150)
length(C_flux.depth.200$C_avg.200)
length(C_flux.depth.300$C_avg.300)
length(C_flux.depth.400$C_avg.400)
```

Mean and SE of each depth of C-flux

```{r, echo=FALSE}
muCflux150 <- mean(C_flux.depth.150$C_avg.150) #focusing on mean of C-avg at depth 150
s.e150c <- sd(C_flux.depth.150$C_avg.150) / sqrt(314)  #need to find s.e

muCflux200 <- mean(C_flux.depth.200$C_avg.200) #focusing on mean of C-avg at depth 200
s.e200c <- sd(C_flux.depth.200$C_avg.200) / sqrt(304)

muCflux300 <- mean(C_flux.depth.300$C_avg.300) #focusing on mean of C-avg at depth 300
s.e300c <- sd(C_flux.depth.300$C_avg.300) / sqrt(305)

muCflux400 <- mean(C_flux.depth.400$C_avg.400) #focusing on mean of C-avg at depth 400
s.e400c <- sd(C_flux.depth.400$C_avg.400) / sqrt(18)

bar.Cflux <- data.frame(c("dep150","dep200","dep300","dep400"), c(muCflux150,muCflux200,muCflux300,muCflux400), c(s.e150c,s.e200c,s.e300c,s.e400c))
colnames(bar.Cflux)[1] <- "Depth"
colnames(bar.Cflux)[2] <- "C_flux.Mean"
colnames(bar.Cflux)[3] <- "C_flux.SE"
bar.Cflux
```

Graph of C-flux

```{r, echo = FALSE}
library(ggplot2)
library(dplyr)

xval <- bar.Cflux$Depth #character objects need quotes
yval <- bar.Cflux$`C_flux.Mean`

ggplot()+geom_col(bar.Cflux, mapping=aes(x= Depth, y = C_flux.Mean), color="#e9ecef", alpha=0.6,) +                                     
xlab("Depth (m)") + ylab("Mean of C Flux(mg carbon m^-2 day^-1)") + ggtitle("Fig 1")               
```

*C-flux decreasing with depth*

<br>

n values of P-flux at each depth

```{r, echo = FALSE}
#n values for P-flux
length(P_flux.depth.150$P_avg.150)
length(P_flux.depth.200$P_avg.200)
length(P_flux.depth.300$P_avg.300)
length(P_flux.depth.400$P_avg.400)
```


Mean and SE of each depth of P-flux

```{r, echo=FALSE}
muPflux150 <- mean(P_flux.depth.150$P_avg.150) #focusing on mean of P-avg at depth 150
s.e150p <- sd(P_flux.depth.150$P_avg.150) / sqrt(109)  #need to find s.e

muPflux200 <- mean(P_flux.depth.200$P_avg.200) #focusing on mean of P-avg at depth 200
s.e200p <- sd(P_flux.depth.200$P_avg.200) / sqrt(106)

muPflux300 <- mean(P_flux.depth.300$P_avg.300) #focusing on mean of P-avg at depth 300
s.e300p <- sd(P_flux.depth.300$P_avg.300) / sqrt(105)

bar.Pflux <- data.frame(c("dep150","dep200","dep300"), c(muPflux150,muPflux200,muPflux300), c(s.e150p,s.e200p,s.e300p))
colnames(bar.Pflux)[1] <- "Depth"
colnames(bar.Pflux)[2] <- "P_flux.Mean"
colnames(bar.Pflux)[3] <- "P_flux.SE"
bar.Pflux
```

Graph of P-flux 

```{r, echo = FALSE}
library(ggplot2)
library(dplyr)

xval <- bar.Pflux$Depth #character objects need quotes
yval <- bar.Pflux$`P_flux.Mean`

ggplot()+geom_col(bar.Pflux, mapping=aes(x= Depth, y = P_flux.Mean), color="#e9ecef", alpha=0.6,) +                                     
xlab("Depth (m)") + ylab("Mean of P Flux(mg phospohorous m^-2 day^-1)") + ggtitle("Fig 2")                    
```

*P-flux decreaing with depth*

<br>

n value of N-flux at each depth

```{r, echo = FALSE}
#n values for N-flux
length(N_flux.depth.150$N_avg.150)
length(N_flux.depth.200$N_avg.200)
length(N_flux.depth.300$N_avg.300)
length(N_flux.depth.400$N_avg.400)
```

Mean and SE of each depth of N-flux

```{r, echo=FALSE}
muNflux150 <- mean(N_flux.depth.150$N_avg.150) #focusing on mean of P-avg at depth 150
s.e150n <- sd(N_flux.depth.150$N_avg.150) / sqrt(312)  #need to find s.e

muNflux200 <- mean(N_flux.depth.200$N_avg.200) #focusing on mean of P-avg at depth 200
s.e200n <- sd(N_flux.depth.200$N_avg.200) / sqrt(302)

muNflux300 <- mean(N_flux.depth.300$N_avg.300) #focusing on mean of P-avg at depth 300
s.e300n <- sd(N_flux.depth.300$N_avg.300) / sqrt(303)

muNflux400 <- mean(N_flux.depth.400$N_avg.400) #focusing on mean of C-avg at depth 400
s.e400n <- sd(N_flux.depth.400$N_avg.400) / sqrt(18)

bar.Nflux <- data.frame(c("dep150","dep200","dep300","dep400"), c(muNflux150,muNflux200,muNflux300,muNflux400), c(s.e150n,s.e200n,s.e300n,s.e400n))
colnames(bar.Nflux)[1] <- "Depth"
colnames(bar.Nflux)[2] <- "N_flux.Mean"
colnames(bar.Nflux)[3] <- "N_flux.SE"
bar.Nflux
```

Graph of N-flux

```{r, echo= FALSE}
library(ggplot2)
library(dplyr)

xval <- bar.Nflux$Depth #character objects need quotes
yval <- bar.Nflux$`N_flux.Mean`

ggplot()+geom_col(bar.Nflux, mapping=aes(x= Depth, y = N_flux.Mean), color="#e9ecef", alpha=0.6,) +                                     
xlab("Depth (m)") + ylab("Mean of N Flux(mg nitrogen m^-2 day^-1)") + ggtitle("Fig 3")               
```

*N-flux decreasing with depth*

<br>

n value for M-flux at each depth 

```{r, echo=FALSE}
#n values for M-flux
length(M_flux.depth.150$M_avg.150)
length(M_flux.depth.200$M_avg.200)
length(M_flux.depth.300$M_avg.300)
length(M_flux.depth.400$M_avg.400)
```

Mean and SE of each depth of M-flux

```{r, echo=FALSE}
muMflux150 <- mean(M_flux.depth.150$M_avg.150) #focusing on mean of P-avg at depth 150
s.e150m <- sd(M_flux.depth.150$M_avg.150) / sqrt(314)  #need to find s.e

muMflux200 <- mean(M_flux.depth.200$M_avg.200) #focusing on mean of P-avg at depth 200
s.e200m <- sd(M_flux.depth.200$M_avg.200) / sqrt(305)

muMflux300 <- mean(M_flux.depth.300$M_avg.300) #focusing on mean of P-avg at depth 300
s.e300m <- sd(M_flux.depth.300$M_avg.300) / sqrt(305)

muMflux400 <- mean(M_flux.depth.400$M_avg.400) #focusing on mean of C-avg at depth 400
s.e400m <- sd(M_flux.depth.400$M_avg.400) / sqrt(17)

bar.Mflux <- data.frame(c("dep150","dep200","dep300","dep400"), c(muMflux150,muMflux200,muMflux300,muMflux400), c(s.e150m,s.e200m,s.e300m,s.e400m))
colnames(bar.Mflux)[1] <- "Depth"
colnames(bar.Mflux)[2] <- "M_flux.Mean"
colnames(bar.Mflux)[3] <- "M_flux.SE"
bar.Mflux
```

Graph of M-flux

```{r, echo = FALSE}
library(ggplot2)
library(dplyr)


xval <- bar.Mflux$Depth #character objects need quotes
yval <- bar.Mflux$`M_flux.Mean`

ggplot()+geom_col(bar.Mflux, mapping=aes(x= Depth, y = M_flux.Mean), color="#e9ecef", alpha=0.6,) +                                     
xlab("Depth (m)") + ylab("Mean of M Flux(mg mass m^-2 day^-1)") + ggtitle("Fig 4")          
```

*M-flux decreasing with depth*

<br>

### Distributionand box plot of our data by depth 

Checking for normality and outliers in flux distribution

Log transfromation was needed for all Fluxes 

```{r,eval=TRUE, echo=FALSE}
# Checking for normaility and no outliers in Carbon Flux 
par(mfrow=c(1,4))
hist((C_flux.depth.150$C_avg.150), main ="Fig 5 C Flux depth 150")
hist((C_flux.depth.200$C_avg.200), main ="Fig 6 C Flux depth 200")
hist((C_flux.depth.300$C_avg.300), main ="Fig 7 C Flux depth 300")
hist((C_flux.depth.400$C_avg.400), main ="Fig 8 C Flux depth 400")

# using natural log to Transform the data 
par(mfrow=c(1,4))
hist(log(C_flux.depth.150$C_avg.150), main ="Fig 9 C Flux depth 150 (log)")
hist(log(C_flux.depth.200$C_avg.200), main ="Fig 10 C Flux depth 200 (log)")
hist(log(C_flux.depth.300$C_avg.300), main ="Fig 11 C Flux depth 300 (log)")
hist(log(C_flux.depth.400$C_avg.400), main ="Fig 12 C Flux depth 400 (log)")

# Checking for outliers
par(mfrow=c(1,4))
boxplot(log(C_flux.depth.150$C_avg.150), main ="Fig 13 C Flux depth 150 (log)")
boxplot(log(C_flux.depth.200$C_avg.200), main ="Fig 14 C Flux depth 200 (log)")
boxplot(log(C_flux.depth.300$C_avg.300), main ="Fig 15 C Flux depth 300 (log)")
boxplot(log(C_flux.depth.400$C_avg.400), main ="Fig 16 C Flux depth 400 (log)")
```

*boxplot means do not overlap, but box sizes for 150, 200, and 300 seem to be similar in box size as well as whisker length which means that they could be good predictors of each other and do not break homoscedasticity. However, the 400 depth has a lot of overlap and a very different shape which could break homosedasticity*

<br>

```{r,eval=TRUE, echo=FALSE}
# Checking for normaility and no outliers in Nitrogen Flux 
par(mfrow=c(1,4))
hist((N_flux.depth.150$N_avg.150), breaks = "FD", main ="Fig 17 N Flux depth 150")
hist((N_flux.depth.200$N_avg.200), breaks = "FD", main ="Fig 18 N Flux depth 200")
hist((N_flux.depth.300$N_avg.300), breaks = "FD", main ="Fig 19 N Flux depth 300")
hist((N_flux.depth.400$N_avg.400), breaks = "FD", main ="Fig 20 N Flux depth 400")

# using natural log to Transform the data 
par(mfrow=c(1,4))
hist(log(N_flux.depth.150$N_avg.150), main ="Fig 21 N Flux depth 150 (log)")
hist(log(N_flux.depth.200$N_avg.200), main ="Fig 22 N Flux depth 200 (log)")
hist(log(N_flux.depth.300$N_avg.300), main ="Fig 23 N Flux depth 300 (log)")
hist(log(N_flux.depth.400$N_avg.400), main ="Fig 24 N Flux depth 400 (log)")

# Checking for outliers
par(mfrow=c(1,4))
boxplot(log(N_flux.depth.150$N_avg.150), main ="Fig 25 N Flux depth 150 (log)")
boxplot(log(N_flux.depth.200$N_avg.200), main ="Fig 26 N Flux depth 200 (log)")
boxplot(log(N_flux.depth.300$N_avg.300), main ="Fig 27 N Flux depth 300 (log)")
boxplot(log(N_flux.depth.400$N_avg.400), main ="Fig 28 N Flux depth 400 (log)")
```

*boxplot means do not too seem to overlab too much for 150 and 200, but ther is a bit of overlap in 200 and 300. 150, 200, and 300 seem to be similar in box size as well as whisker length which means that they could be good predictors of each other and do not break homoscedasticity. However, the 400 depth has a lot of overlap and a very different shape which could break homosedasticity*

<br>

```{r,eval=TRUE, echo=FALSE}
# Checking for normaility and no outliers in Phosporous Flux 
par(mfrow=c(1,3))
hist((P_flux.depth.150$P_avg.150), breaks = "FD", main ="Fig 29 P Flux depth 150")
hist((P_flux.depth.200$P_avg.200), breaks = "FD", main ="Fig 30 P Flux depth 200")
hist((P_flux.depth.300$P_avg.300), breaks = "FD", main ="Fig 31 P Flux depth 300")

# using natural log to Transform the data 
par(mfrow=c(1,3))
hist(log(P_flux.depth.150$P_avg.150), main ="Fig 32 P Flux depth 150 (log)")
hist(log(P_flux.depth.200$P_avg.200), main ="Fig 33 P Flux depth 200 (log)")
hist(log(P_flux.depth.300$P_avg.300), main ="Fig 34 P Flux depth 300 (log)")

# Checking for outliers
par(mfrow=c(1,3))
boxplot(log(P_flux.depth.150$P_avg.150), main ="Fig 35 P Flux depth 150 (log)")
boxplot(log(P_flux.depth.200$P_avg.200), main ="Fig 36 P Flux depth 200 (log)")
boxplot(log(P_flux.depth.300$P_avg.300), main ="Fig 37 P Flux depth 300 (log)")
```

*boxplot means seem to have some overlap. They are similar in box size, but the concern is the overlap, making them not good predictors of one another and potentially breaking homosedasticity*

```{r,eval=TRUE, echo=FALSE}
# Checking for normaility and no outliers in Mass Flux 
par(mfrow=c(1,4))
hist((M_flux.depth.150$M_avg.150), breaks = "FD", main ="Fig 38 M Flux depth 150")
hist((M_flux.depth.200$M_avg.200), breaks = "FD", main ="Fig 39 M Flux depth 200")
hist((M_flux.depth.300$M_avg.300), breaks = "FD", main ="Fig 40 M Flux depth 300")
hist((M_flux.depth.400$M_avg.400), breaks = "FD", main ="Fig 41 M Flux depth 400")

# using natural log to Transform the data 
par(mfrow=c(1,4))
hist(log(M_flux.depth.150$M_avg.150), main ="Fig 42 M Flux depth 150 (log)")
hist(log(M_flux.depth.200$M_avg.200), main ="Fig 43 M Flux depth 200 (log)")
hist(log(M_flux.depth.300$M_avg.300), main ="Fig 44 M Flux depth 300 (log)")
hist(log(M_flux.depth.400$M_avg.400), main ="Fig 45 M Flux depth 400 (log)")

# Checking for outliers
par(mfrow=c(1,4))
boxplot(log(M_flux.depth.150$M_avg.150), main ="Fig 46 M Flux depth 150 (log)")
boxplot(log(M_flux.depth.200$M_avg.200), main ="Fig 47 M Flux depth 200 (log)")
boxplot(log(M_flux.depth.300$M_avg.300), main ="Fig 48 M Flux depth 300 (log)")
boxplot(log(M_flux.depth.400$M_avg.400), main ="Fig 49 M Flux depth 400 (log)")
```

*boxplot means seem to have some overlap. They are similar in box size, but the concern is the overlap, making them not good predictors of one another and potentially breaking homosedasticity*

*Since many of the 400 m depth distrubutions were not normal, even after transformation and have small n, they will not be used in the hypothesis testing* 

<br>

### Paired sample t test for each depth and the depth below it 

This is a paired test because samples were collected on the same cruise and at the same location. So for each flux value at one depth, there was a flux value collected at a different depth at the same location!
Data frames were merged based on cruise, year, and location to have the same number of values.  

For a paired t test to be preformed it must meet these assumptions:

$\overline{Y_1}$ - $\overline{Y_2}$ = $\overline{D}$

+ The dependent variable must be continuous (interval/ratio). $\checkmark$

+ The observations are independent of one another. $\checkmark$ 

+ The dependent variable ($\overline{D}$) should be approximately normally distributed. $\Box$ ?

+ The dependent variable ($\overline{D}$) should not contain any outliers. $\Box$ ?

<br>

Merging data bases for hypothesis test and Creating $\overline{D}$ for each paired group

```{r ,echo = FALSE}
#create D-bar for each paired group

C.depth.150.200 <- merge(C_flux.depth.150,C_flux.depth.200,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.C.150.200 <- muCflux150 - muCflux200
C.depth.150.200$D <- C.depth.150.200$C_avg.150 - C.depth.150.200$C_avg.200

C.depth.200.300 <- merge(C_flux.depth.200,C_flux.depth.300,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.C.200.300 <- muCflux200 - muCflux300
C.depth.200.300$D <- C.depth.200.300$C_avg.200 - C.depth.200.300$C_avg.300

N.depth.150.200 <- merge(N_flux.depth.150,N_flux.depth.200,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.N.150.200 <- muNflux150 - muNflux200
N.depth.150.200$D <- N.depth.150.200$N_avg.150 - N.depth.150.200$N_avg.200

N.depth.200.300 <- merge(N_flux.depth.200,N_flux.depth.300,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.N.200.300 <- muNflux200 - muNflux300
N.depth.200.300$D <- N.depth.200.300$N_avg.200 - N.depth.200.300$N_avg.300

P.depth.150.200 <- merge(P_flux.depth.150,P_flux.depth.200,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.P.150.200 <- muPflux150 - muPflux200
P.depth.150.200$D <- P.depth.150.200$P_avg.150 - P.depth.150.200$P_avg.200

P.depth.200.300 <- merge(P_flux.depth.200,P_flux.depth.300,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.P.200.300 <- muPflux200 - muPflux300
P.depth.200.300$D <- P.depth.200.300$P_avg.200 - P.depth.200.300$P_avg.300

M.depth.150.200 <- merge(M_flux.depth.150,M_flux.depth.200,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.M.150.200 <- muMflux150 - muMflux200
M.depth.150.200$D <- M.depth.150.200$M_avg.150 - M.depth.150.200$M_avg.200

M.depth.200.300 <- merge(M_flux.depth.200,M_flux.depth.300,by = c("cr","yymmdd1","yymmdd2","Lat2","Lat2.1","Long1","Long2"))
D_bar.M.200.300 <- muMflux200 -muMflux300
M.depth.200.300$D <- M.depth.200.300$M_avg.200 - M.depth.200.300$M_avg.300

D_bar.mean <- data.frame(c("dep150.200","dep200.300"), c(D_bar.C.150.200, D_bar.C.200.300), c(D_bar.N.150.200, D_bar.N.200.300), c(D_bar.P.150.200 ,D_bar.P.200.300 ), c(D_bar.M.150.200 ,D_bar.M.200.300))
colnames(D_bar.mean)[1] <- "Depth.Diff"
colnames(D_bar.mean)[2] <- "C_flux"
colnames(D_bar.mean)[3] <- "N_flux"
colnames(D_bar.mean)[4] <- "P_flux"
colnames(D_bar.mean)[5] <- "M_flux"
D_bar.mean
```

Checking the distribution of the $\overline{D}$ for each flux 

```{r, echo= FALSE}
#check distribution of D (difference between paried depth samples)

# Carbon 
par(mfrow=c(1,3))
hist(C.depth.150.200$D, breaks = "FD")
hist(log(C.depth.150.200$D), breaks = "FD", main ="Fig 50 C.depth.150.200$D_bar") #try lo transform 
boxplot(log(C.depth.150.200$D)) #lots of outliers 
```

*Cdepth (150.200) is not very normal, but log transformation increases normality. Outliers present in box plot*

```{r, echo=FALSE}
# Carbon 
par(mfrow=c(1,3))
hist(C.depth.200.300$D, breaks = "FD")
hist(log(C.depth.200.300$D), breaks = "FD", main ="Fig 51 C.depth.200.300$D_bar") #try lo transform 
boxplot(log(C.depth.200.300$D)) #lots of outliers 
```

*Cdepth (200.300) is not normal, but log transformation increases normality. Outliers present in box plot*

```{r, echo=FALSE}
# Nitrogen
par(mfrow=c(1,3))
hist(N.depth.150.200$D, breaks = "FD")
hist(log(N.depth.150.200$D), breaks = "FD", main ="Fig 52 N.depth.150.200$D_bar") #try lo transform 
boxplot(log(N.depth.150.200$D)) #lots of outliers 
```

*Ndepth (150.200) is not very normal, but log transformation increases normality. Outliers present in box plot*

```{r, echo=FALSE}
# Nitrogen
par(mfrow=c(1,3))
hist(N.depth.200.300$D, breaks = "FD")
hist(log(N.depth.200.300$D), breaks = "FD", main ="Fig 53 N.depth.200.300$D_bar") #try lo transform 
boxplot(log(N.depth.200.300$D)) #lots of outliers 
```

*Ndepth (200.300) is skewed, but log transformation increases normality. Outliers present in box plot*

```{r,echo=FALSE}
# Phosphorous
par(mfrow=c(1,3))
hist(P.depth.150.200$D, breaks = "FD")
hist(log(P.depth.150.200$D), breaks = "FD", main ="Fig 54 P.depth.150.200$D_bar") #try lo transform 
boxplot(log(P.depth.150.200$D)) #lots of outliers 
```

*Pdepth (150.200) is not very normal, but log transformation increases normality. Outliers present in box plot*

```{r,echo=FALSE}
# Phosporous
par(mfrow=c(1,3))
hist(P.depth.200.300$D, breaks = "FD")
hist(log(P.depth.200.300$D), breaks = "FD", main ="Fig 55 P.depth.200.300$D_bar") #try lo transform 
boxplot(log(P.depth.200.300$D)) #lots of outliers 
```

*Pdepth (200.300) is not very normal, but log transformation increases normality. NO outliers present in box plot*

```{r,echo=FALSE}
# Mass 
par(mfrow=c(1,3))
hist(M.depth.150.200$D, breaks = "FD")
hist(log(M.depth.150.200$D), breaks = "FD", main ="Fig 56 M.depth.150.200$D_bar") #try lo transform 
boxplot(log(M.depth.150.200$D)) #lots of outliers 
```

*Mdepth (150.200) is fairly normal, but log transformation increases normality. Outliers present in box plot*

```{r,echo=FALSE}
# Mass
par(mfrow=c(1,3))
hist(M.depth.200.300$D, breaks = "FD")
hist(log(M.depth.200.300$D), breaks = "FD", main ="Fig 57 C.depth.200.300$D_bar") #try lo transform 
boxplot(log(M.depth.200.300$D)) #lots of outliers 
```

*Mdepth (200.300) is not normal, but log transformation increases normality. Outliers present in box plot*

<br>

Proceed with hypothesis test of log transformed data

#### Hyp 1

$\mu_1$ = mean Carbon flux at depth 150
$\mu_2$ = mean Carbon flux at depth 200

$H_0$ : Carbon flux does not change between 150 and 200 meter. $\mu_1$ = $\mu_2$
$H_1$ : Carbon flux is lower at 200 meter then at 150 meter. $\mu_1$ > $\mu_2$

```{r, echo=FALSE}
# hyp test 1
t.test(log(C.depth.150.200$C_avg.150) ,log(C.depth.150.200$C_avg.200), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 2

$\mu_1$ = mean Carbon flux at depth 200
$\mu_2$ = mean Carbon flux at depth 300

$H_0$ : Carbon flux does not change between 200 and 300 meter. $\mu_1$ = $\mu_2$
$H_1$ : Carbon flux is lower at 300 meter then at 200 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 2
t.test(log(C.depth.200.300$C_avg.200) ,log(C.depth.200.300$C_avg.300), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*very low pval. We reject the null, significant*

#### Hyp 3

$\mu_1$ = mean Nitrogen flux at depth 150
$\mu_2$ = mean Nitrogen flux at depth 200

$H_0$ : Nitrogen flux does not change between 150 and 200 meter. $\mu_1$ = $\mu_2$
$H_1$ : Nitrogen flux is lower at 200 meter then at 150 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 3
t.test(log(N.depth.150.200$N_avg.150) ,log(N.depth.150.200$N_avg.200), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 4

$\mu_1$ = mean Nitrogen flux at depth 200
$\mu_2$ = mean Nitrogen flux at depth 300

$H_0$ : Nitrogen flux does not change between 200 and 300 meter. $\mu_1$ = $\mu_2$
$H_1$ : Nitrogen flux is lower at 300 meter then at 200 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 4
t.test(log(N.depth.200.300$N_avg.200) ,log(N.depth.200.300$N_avg.300), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 5

$\mu_1$ = mean Phosporous flux at depth 150
$\mu_2$ = mean Phosporous flux at depth 200

$H_0$ : Phosporous flux does not change between 150 and 200 meter. $\mu_1$ = $\mu_2$
$H_1$ : Phosporous flux is lower at 200 meter then at 150 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 5
t.test(log(P.depth.150.200$P_avg.150) ,log(P.depth.150.200$P_avg.200), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 6

$\mu_1$ = mean Phosporous flux at depth 200
$\mu_2$ = mean Phosporous flux at depth 300

$H_0$ : Phosporous flux does not change between 200 and 300 meter. $\mu_1$ = $\mu_2$
$H_1$ : Phosporous flux is lower at 300 meter then at 200 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 6
t.test(log(P.depth.200.300$P_avg.200) ,log(P.depth.200.300$P_avg.300), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 7

$\mu_1$ = mean Mass flux at depth 150
$\mu_2$ = mean Mass flux at depth 200

$H_0$ : Mass flux does not change between 150 and 200 meter. $\mu_1$ = $\mu_2$
$H_1$ : Mass flux is lower at 200 meter then at 150 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 7
t.test(log(M.depth.150.200$M_avg.150) ,log(M.depth.150.200$M_avg.200), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

#### Hyp 8

$\mu_1$ = mean Mass flux at depth 200
$\mu_2$ = mean Mass flux at depth 300

$H_0$ : Mass flux does not change between 200 and 300 meter. $\mu_1$ = $\mu_2$
$H_1$ : Mass flux is lower at 300 meter then at 200 meter. $\mu_1$ > $\mu_2$

```{r,echo=FALSE}
# hyp test 8
t.test(log(M.depth.200.300$M_avg.200) ,log(M.depth.200.300$M_avg.300), alternative = "greater", paired = TRUE, var.equal = TRUE)
```

*super low p-value,significant, reject the null*

<br>

### Simple Linear Regression via LS

How does each flux predict Mass Flux? 

Regression Model: $Y_i$ = $\beta_0$ + $\beta_1x_i$ + $\epsilon_i$ where $\epsilon_i$ ~ $N(0,\sigma^2)$

Best Fit line: $f(x)$ = $\hat{\beta_0}$ + $\hat{\beta_1}x$

```{r,echo=FALSE}
# plotting each nutrient flux against mass flux

#plot(Data.noNA) # we see some relationships between mass flux and the rest of the nutrient fluxes
par(mfrow=c(1,3))
plot(log(Data.noNA$C_avg),log(Data.noNA$M_avg), main ="Fig 58 M v. C") #good linearity, but clumping
lmfit_C.M <- lm(log(M_avg) ~ log(C_avg), data = Data.noNA)
summary(lmfit_C.M)
abline(lmfit_C.M)

plot(log(Data.noNA$N_avg),log(Data.noNA$M_avg), main ="Fig 59 M v. N") # alright linearity, still clumping 
lmfit_N.M <- lm(log(M_avg) ~ log(N_avg), data = Data.noNA)
summary(lmfit_N.M)
abline(lmfit_N.M)

plot(log(Data.noNA$P_avg),log(Data.noNA$M_avg), main ="Fig 60 M v. P") # worse, still clumping 
lmfit_P.M <- lm(log(M_avg) ~ log(P_avg), data = Data.noNA)
summary(lmfit_P.M)
abline(lmfit_P.M)

```

*Both predictor and predictee had to be log transformed in order to make this data more linear with less clumping for all fluxes*

*For C flux, multilple r squared is 0.7405, so pretty good fit. Some clumping still*

*For N flux, multiple r squared is 0.6446, so still pretty decent, just not as strong as C flux. Some clumping still*

*For P flux, multiple r squared is 0.3592, so very poor fit and a lot of clumping*

<br>

Carbon flux seems to be the best predictor of Mass flux. Lets run some EDA. 

```{r,echo=FALSE}
#Carbon EDA
resids <- resid( lmfit_C.M ) # extract epsilon_hats
fit <- fitted ( lmfit_C.M ) # extract y_hats

par(mfrow=c(1,2))

hist(resids, breaks=20)
qqnorm(resids)
qqline(resids) # add straight line from true normal

plot(resids, main="Fig 61 resid vs i") 
abline(h=0) # mean of epsilon_hat

plot(x=fit, y=resids, main="Fig 62 resid vs y_hat")
abline(h=0)

```

*Not very normal, linearity is okay, but not great, both residual are not very evenly scattered and there is clumping around the line, so not heteroscedasicity, trifecta is broken* 

 <br>
 
Lets compare these EDA's to that of Nitrogen Flux and Mass Flux. Nitrogen Flux was also a strong predictor of Mass Flux. 

```{r,echo=FALSE}
#Nitrogen EDA
resids <- resid( lmfit_N.M ) # extract epsilon_hats
fit <- fitted ( lmfit_N.M ) # extract y_hats

par(mfrow=c(1,2))

hist(resids, breaks=20)
qqnorm(resids)
qqline(resids) # add straight line from true normal

plot(resids, main="Fig 63 resid vs i") 
abline(h=0) # mean of epsilon_hat

plot(x=fit, y=resids, main="Fig 64 resid vs y_hat")
abline(h=0)

```

*Not very normal, linearity is okay, but not great, both residual are not very evenly scattered and there is clumping around the line, so not heteroscedasicity, trifecta is broken about the same as C flux* 
 

<br> 

Lets now compare these to Phosphorous Flux, a weak predcitor of Mass Flux. 

```{r,echo=FALSE}
#Phosphorus EDA
resids <- resid( lmfit_P.M ) # extract epsilon_hats
fit <- fitted ( lmfit_P.M ) # extract y_hats

par(mfrow=c(1,2))

hist(resids, breaks=20)
qqnorm(resids)
qqline(resids) # add straight line from true normal

plot(resids, main="Fig 65 resid vs i") 
abline(h=0) # mean of epsilon_hat

plot(x=fit, y=resids, main="Fig 66 resid vs y_hat")
abline(h=0)
```

*Somewhat normal, linearity is okay, but not great, both residual are not very evenly scattered and there is clumping around the line, so not heteroscedasicity, trifecta is broken* 

<br>

Do we see collinearity between the different fluxes that are predicting mass flux? Should we combine the fluxes? 

Regression Model: $Y_i$ = $\beta_0$ + $\beta_1x_i$ + $\epsilon_i$ where $\epsilon_i$ ~ $N(0,\sigma^2)$

Best Fit line: $f(x)$ = $\hat{\beta_0}$ + $\hat{\beta_1}x$

```{r,echo=FALSE}
#Collinearity??
plot(Data.noNA) # we see collinearity between Carbon and Nitrogen
Data.noNA$flux <- Data.noNA$C_avg - Data.noNA$N_avg  #combine the fluxes

lmfit.flux <- lm(log(M_avg) ~ log(flux),
         data=Data.noNA)
summary(lmfit.flux)
plot(log(Data.noNA$flux), log(Data.noNA$M_avg), main ="Fig 67")
abline(lmfit.flux)

resids <- resid( lmfit.flux ) # extract epsilon_hats
fit <- fitted ( lmfit.flux ) # extract y_hats

par(mfrow=c(1,2))

hist(resids, breaks=20, main ="Fig 68")
qqnorm(resids)
qqline(resids) # add straight line from true normal

plot(resids, main="Fig 69 resid vs i") 
abline(h=0) # mean of epsilon_hat

plot(x=fit, y=resids, main="Fig 69 resid vs y_hat")
abline(h=0)

```

*We see collineary between Nitrogen and Carbon flux predictors, so they were combined into a sing flux categorie to predict mass flux*

*add comment of EDA ouput* 

<br>

How does depth affect flux? 

Regression Model: $Y_i$ = $\beta_0$ + $\beta_1x_i$ + $\epsilon_i$ where $\epsilon_i$ ~ $N(0,\sigma^2)$

Best Fit line: $f(x)$ = $\hat{\beta_0}$ + $\hat{\beta_1}x$

```{r,echo=FALSE}
# dept v. C_avg

par(mfrow=c(1,4))

plot(Data.noNA$dep, log(Data.noNA$C_avg), main ="Fig 70")
lmfit_Dep.C <- lm(log(C_avg) ~ dep, data = Data.noNA)
summary(lmfit_Dep.C)
abline(lmfit_Dep.C)

plot(Data.noNA$dep, log(Data.noNA$N_avg), main= "Fig 71")
lmfit_Dep.N <- lm(log(N_avg) ~ dep, data = Data.noNA)
summary(lmfit_Dep.N)
abline(lmfit_Dep.N)

plot(Data.noNA$dep, log(Data.noNA$P_avg),  main= "Fig 72")
lmfit_Dep.P <- lm(log(P_avg) ~ dep, data = Data.noNA)
summary(lmfit_Dep.P)
abline(lmfit_Dep.P)

plot(Data.noNA$dep, log(Data.noNA$M_avg),  main= "Fig 73")
lmfit_Dep.M <- lm(log(M_avg) ~ dep, data = Data.noNA)
summary(lmfit_Dep.M)
abline(lmfit_Dep.M)
```

*shows that as depth decreases so does flux, depth can be a predictor of flux*

<br>

### Multiple regression 

Regression Model: $Y_i$ = $\beta_0$ + $\beta_1x_i$ + ... + $\beta_{p-1}x_{i,p-1}$ + $\epsilon_i$ = $X'_i\beta$ + $\epsilon_i$ where $\epsilon_i$ ~ $N(0,\sigma^2)$

Best Fit line: $f(x)$ = $\hat{\beta_0}$ + $\hat{\beta_1}x$

```{r,echo=FALSE}
#multiple regression
lmfit.MR <- lm(log(M_avg) ~ log(flux) + dep, data = Data.noNA)
summary(lmfit.MR)

resids <- resid( lmfit.MR ) # extract epsilon_hats
fit <- fitted ( lmfit.MR ) # extract y_hats

par(mfrow=c(1,2))

hist(resids, breaks=20,  main= "Fig 74")
qqnorm(resids)
qqline(resids) # add straight line from true normal

plot(resids, main="Fig 75 resid vs i") 
abline(h=0) # mean of epsilon_hat

plot(x=fit, y=resids, main="Fig 76 resid vs y_hat")
abline(h=0)
```

*Fairly normal and linear, but very clustered for residules*

<br>

which one is better?

```{r,echo=FALSE}
#anova 1
smaller <- lmfit.flux; larger <- lmfit.MR
anova(smaller, larger)
```

*There is no significance difference in the first anova model, our p-value is to large to assume that lossing df due to an extra parameter is worthwhile*

```{r,echo=FALSE}
#anova 2
smaller.1 <- lmfit_Dep.M; larger <- lmfit.MR
anova(smaller.1, larger)
```

*However there our p-value is small in our second anova model indicates that losing df due to an extra paramter is worthwhile, or signiicantly improves the fit*

### ANCOVA 

```{r,echo=FALSE}
#we want to make predictions on the Mass average flux. 

# we want to compare this against depth and C,N,P fluxes 

# Depth is categorical 
# N,P,C are numerical 

library(psych) # for `pairs.panels()`
library(lattice)

ANOCOVA.data <- subset(Data.noNA, select = c("dep", "M_avg", "C_avg","N_avg","P_avg"))
attach(ANOCOVA.data)

summary(ANOCOVA.data)

pairs.panels(data.frame(as.factor(dep),log(C_avg),log(N_avg),log(P_avg),log(M_avg)), main = "Fig 77")

xyplot(log(M_avg) ~ log(C_avg) | as.factor(dep), 
                  main="Fig 78: Activity level-specific scatterplots"
           )

    xyplot(log(M_avg) ~ log(C_avg), groups=as.factor(dep), 
                  auto.key=TRUE,
                  main="Fig 79: Scatterplot with color=group level"
           )
    
    xyplot(log(M_avg) ~ log(C_avg), groups=as.factor(dep), 
                  type=c("p","r"), # `p` for _points_, `r` for _regression line_
                                   # see https://stackoverflow.com/questions/12972039/plotting-xyplot-with-regression-line-on-lattice-graphics for more
                  auto.key=TRUE,
                  main="Fig 80: Three standalone depth level-specific `lm()` fits"
           )
```

*After log transforming data, C, N, P, and M distributions look much more noraml. Linearlity is looking better, especially for C and N. Activity level specific scatterplots highlight the interaction with C and M through depths and have somewhat of a linear reationship*

```{r,echo=FALSE}
#reformat yymmdd so that r can better use it blocking factors 

# only yymmdd1 was used to create new year and month columns since yymmdd1 and yymmdd2 sampled were only a couple days apart and were averaged out in flux columns

Data.noNA$Date <- as.Date(paste(substr(Data.noNA$yymmdd1,1,4),
                                         substr(Data.noNA$yymmdd1,5,6),
                                         substr(Data.noNA$yymmdd1,7,8), sep = "-"),
                                   format = '%Y-%m-%d')

Data.noNA$Year <- substr(Data.noNA$yymmdd1,1,4)

install.packages("lubridate")
library(lubridate)                            
Data.noNA$month <- as.Date(paste(substr(Data.noNA$yymmdd1,5,6),
                              substr(Data.noNA$yymmdd1,7,8), sep = "-"),
                        format = '%m-%d')           
Data.noNA$month <- round_date(Data.noNA$month, unit = "month")
Data.noNA$month <- format(Data.noNA$month,format = "%Y-%b-%d")
Data.noNA$month <- substr(paste(Data.noNA$month),6,8)

```



```{r,echo=FALSE}
#ANCOVA
ANOCOVA.data <- subset(Data.noNA, select = c("dep", "M_avg", "C_avg","N_avg","P_avg", "Year", "month"))
ANOCOVA.data <- as.vector(ANOCOVA.data)
ANCOVA <- lm(log(M_avg) ~ log(C_avg) + log(N_avg) + log(P_avg) + dep + as.factor(Year) + as.factor(month),data = ANOCOVA.data)
summary(ANCOVA)
plot(ANCOVA, main = "Fig 81") #challen
resids <- resid(ANCOVA)
fit <-fitted(ANCOVA)
```

*These do not present strong relationships*

<br>

# Results discussion: 

# Limitations:
<<<<<<< HEAD
We had limitations in our data from a lot of N/As that prevented us on running full analyses. If this data had been available, we could have seen much stronger trends in our data. 
=======
>>>>>>> 77f5b323040dadff19269847f97b899c156d3639

# References:

1. B. Szymczycha, Z. Klostowska, M. Lengier, L. Dzierzbicka-Glowacka, Significance of nutrient fluxes via submarine groundwater discharge in the Bay of Puck, southern Baltic Sea. Oceanologia 62, 117-125 (2020).

2. H. C. Zhao, L. Zhang, S. R. Wang, L. X. Jiao, Features and influencing factors of nitrogen and phosphorus diffusive fluxes at the sediment-water interface of Erhai Lake. Environmental Science and Pollution Research 25, 1933-1942 (2018).

3. K. Khan, C. W. Su, R. Tao, L. N. Hao, Urbanization and carbon emission: causality evidence from the new industrialized economies. Environment Development and Sustainability 22, 7193-7213 (2020).

4. C. A. Wynn-Edwards et al., Particle Fluxes at the Australian Southern Ocean Time Series (SOTS) Achieve Organic Carbon Sequestration at Rates Close to the Global Median, Are Dominated by Biogenic Carbonates, and Show No Temporal Trends Over 20-Years. Frontiers in Earth Science 8, 20 (2020).

5. BATS Methods. Chapter 20. Trap collected particle flux with surface tethered traps (2017)

6. BATS Methods. Chapter 1. Introduction (1997).

# Appendix 

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

